{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1oJcJowpli6_l0653Scc4hkPW3MjQMUkg",
      "authorship_tag": "ABX9TyO0Kpd9k/k/jExpY4vFDYge",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoushikCodesWebpages/Emotion_Detection_model/blob/main/Main_model_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QtC2eCqDYqzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2c793d-ea16-4b46-efc9-b14d14b90cfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os"
      ],
      "metadata": {
        "id": "iPl5Q80PYwti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = ['Angry', 'Disgust', 'Fear', \"Happy\" , \"Neutral\" , \"Sad\", 'Surprise']\n",
        "print(\"MAIN\\n\")\n",
        "for emotion in emotions:\n",
        "  def count_images_in_directory(directory_path):\n",
        "      try:\n",
        "          files = os.listdir(directory_path)\n",
        "\n",
        "          image_files = [file for file in files if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "          print(f\"Number of images in '{emotion}': {len(image_files)}\")\n",
        "\n",
        "          return len(image_files)\n",
        "\n",
        "\n",
        "      except Exception as e:\n",
        "\n",
        "          print(f\"An error occurred: {e}\")\n",
        "          return None\n",
        "\n",
        "\n",
        "  directory_path_in_drive = os.path.join('/content/drive/MyDrive/1 virtusa emoji/MODEL/Emo_out',emotion)\n",
        "  print(\"\\n\"+emotion+\"\\n\")\n",
        "  count_images = count_images_in_directory(directory_path_in_drive)\n",
        "\n",
        "  if count_images is not None:\n",
        "      print(f\"Total number of images in the directory: {count_images}\")\n",
        "  else:\n",
        "      print(\"Failed to count images.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsFfdkst2mOB",
        "outputId": "a44cf937-6364-4d50-f858-60be3c31e779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAIN\n",
            "\n",
            "\n",
            "Angry\n",
            "\n",
            "Number of images in 'Angry': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Disgust\n",
            "\n",
            "Number of images in 'Disgust': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Fear\n",
            "\n",
            "Number of images in 'Fear': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Happy\n",
            "\n",
            "Number of images in 'Happy': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Neutral\n",
            "\n",
            "Number of images in 'Neutral': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Sad\n",
            "\n",
            "Number of images in 'Sad': 8\n",
            "Total number of images in the directory: 8\n",
            "\n",
            "Surprise\n",
            "\n",
            "Number of images in 'Surprise': 8\n",
            "Total number of images in the directory: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model = Sequential()"
      ],
      "metadata": {
        "id": "8vdi9QD_hmfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))"
      ],
      "metadata": {
        "id": "ddHqAdXVjxQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "metadata": {
        "id": "ZS_kaIAHhto5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "emotion_model.add(Dropout(0.25))"
      ],
      "metadata": {
        "id": "u-QlDli0huCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.add(Flatten())\n",
        "emotion_model.add(Dense(1024, activation='relu'))\n",
        "emotion_model.add(Dropout(0.5))\n",
        "emotion_model.add(Dense(7, activation='softmax'))"
      ],
      "metadata": {
        "id": "gorl_mvOkXt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "initial_learning_rate = 0.0001\n",
        "lr_schedule = ExponentialDecay(\n",
        "    initial_learning_rate,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9,\n",
        "    staircase=True)"
      ],
      "metadata": {
        "id": "sFXUpSgakf2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.compile(optimizer=Adam(learning_rate=lr_schedule), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "aCF2vMP0kjeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = r\"/content/drive/MyDrive/1 virtusa emoji/MODEL/Emotions_out_2\"\n",
        "val_dir = r\"/content/drive/MyDrive/1 virtusa emoji/MODEL/Emo_out\""
      ],
      "metadata": {
        "id": "3ADMwStQkpiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "QpIgFRQmlDaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=1,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmT6QL8vlEEZ",
        "outputId": "67a0ab86-6b66-4fb7-a663-dfb4ca00f4fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 350 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(48, 48),\n",
        "    batch_size=1,\n",
        "    color_mode=\"grayscale\",\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7rRaAUplI5L",
        "outputId": "8e87397b-a484-4642-b61b-cd5cdeda64e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 56 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmDLOp0OlPSV",
        "outputId": "0e76351b-e617-4b47-933e-8144081dd786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "350/350 [==============================] - 128s 360ms/step - loss: 1.9635 - accuracy: 0.0971 - val_loss: 1.9469 - val_accuracy: 0.1429\n",
            "Epoch 2/100\n",
            "350/350 [==============================] - 25s 70ms/step - loss: 1.9535 - accuracy: 0.1257 - val_loss: 1.9460 - val_accuracy: 0.1429\n",
            "Epoch 3/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 1.9486 - accuracy: 0.1371 - val_loss: 1.9464 - val_accuracy: 0.1429\n",
            "Epoch 4/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 1.9494 - accuracy: 0.1371 - val_loss: 1.9459 - val_accuracy: 0.1429\n",
            "Epoch 5/100\n",
            "350/350 [==============================] - 23s 66ms/step - loss: 1.9501 - accuracy: 0.1257 - val_loss: 1.9457 - val_accuracy: 0.1429\n",
            "Epoch 6/100\n",
            "350/350 [==============================] - 23s 64ms/step - loss: 1.9482 - accuracy: 0.1429 - val_loss: 1.9458 - val_accuracy: 0.1071\n",
            "Epoch 7/100\n",
            "350/350 [==============================] - 25s 71ms/step - loss: 1.9473 - accuracy: 0.1514 - val_loss: 1.9458 - val_accuracy: 0.1429\n",
            "Epoch 8/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 1.9471 - accuracy: 0.1000 - val_loss: 1.9458 - val_accuracy: 0.1429\n",
            "Epoch 9/100\n",
            "350/350 [==============================] - 25s 72ms/step - loss: 1.9472 - accuracy: 0.1257 - val_loss: 1.9456 - val_accuracy: 0.1429\n",
            "Epoch 10/100\n",
            "350/350 [==============================] - 23s 67ms/step - loss: 1.9466 - accuracy: 0.1457 - val_loss: 1.9454 - val_accuracy: 0.1250\n",
            "Epoch 11/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.9467 - accuracy: 0.1343 - val_loss: 1.9454 - val_accuracy: 0.1250\n",
            "Epoch 12/100\n",
            "350/350 [==============================] - 23s 66ms/step - loss: 1.9445 - accuracy: 0.1571 - val_loss: 1.9430 - val_accuracy: 0.2321\n",
            "Epoch 13/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 1.9453 - accuracy: 0.1714 - val_loss: 1.9438 - val_accuracy: 0.1429\n",
            "Epoch 14/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.9339 - accuracy: 0.1971 - val_loss: 1.9384 - val_accuracy: 0.1786\n",
            "Epoch 15/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 1.9065 - accuracy: 0.2343 - val_loss: 1.8965 - val_accuracy: 0.2143\n",
            "Epoch 16/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 1.8084 - accuracy: 0.2857 - val_loss: 1.8130 - val_accuracy: 0.3036\n",
            "Epoch 17/100\n",
            "350/350 [==============================] - 20s 58ms/step - loss: 1.7488 - accuracy: 0.3086 - val_loss: 1.7058 - val_accuracy: 0.3571\n",
            "Epoch 18/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 1.6671 - accuracy: 0.3000 - val_loss: 1.7213 - val_accuracy: 0.3393\n",
            "Epoch 19/100\n",
            "350/350 [==============================] - 23s 66ms/step - loss: 1.5840 - accuracy: 0.3571 - val_loss: 1.6404 - val_accuracy: 0.3750\n",
            "Epoch 20/100\n",
            "350/350 [==============================] - 23s 65ms/step - loss: 1.6048 - accuracy: 0.3714 - val_loss: 1.6283 - val_accuracy: 0.3929\n",
            "Epoch 21/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 1.5407 - accuracy: 0.3857 - val_loss: 1.6193 - val_accuracy: 0.3929\n",
            "Epoch 22/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 1.5362 - accuracy: 0.3886 - val_loss: 1.5660 - val_accuracy: 0.4643\n",
            "Epoch 23/100\n",
            "350/350 [==============================] - 23s 64ms/step - loss: 1.4526 - accuracy: 0.4000 - val_loss: 1.6406 - val_accuracy: 0.4107\n",
            "Epoch 24/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 1.4518 - accuracy: 0.4200 - val_loss: 1.4998 - val_accuracy: 0.4464\n",
            "Epoch 25/100\n",
            "350/350 [==============================] - 24s 67ms/step - loss: 1.4120 - accuracy: 0.4400 - val_loss: 1.5427 - val_accuracy: 0.4821\n",
            "Epoch 26/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 1.4153 - accuracy: 0.4629 - val_loss: 1.5866 - val_accuracy: 0.3393\n",
            "Epoch 27/100\n",
            "350/350 [==============================] - 26s 73ms/step - loss: 1.3441 - accuracy: 0.4400 - val_loss: 1.5572 - val_accuracy: 0.3929\n",
            "Epoch 28/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 1.3381 - accuracy: 0.4800 - val_loss: 1.5548 - val_accuracy: 0.4821\n",
            "Epoch 29/100\n",
            "350/350 [==============================] - 20s 57ms/step - loss: 1.2677 - accuracy: 0.5114 - val_loss: 1.5474 - val_accuracy: 0.3393\n",
            "Epoch 30/100\n",
            "350/350 [==============================] - 23s 64ms/step - loss: 1.2722 - accuracy: 0.5114 - val_loss: 1.5946 - val_accuracy: 0.3929\n",
            "Epoch 31/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.2889 - accuracy: 0.4857 - val_loss: 1.4919 - val_accuracy: 0.4821\n",
            "Epoch 32/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.2804 - accuracy: 0.5057 - val_loss: 1.5166 - val_accuracy: 0.4286\n",
            "Epoch 33/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 1.1960 - accuracy: 0.5257 - val_loss: 1.5741 - val_accuracy: 0.3929\n",
            "Epoch 34/100\n",
            "350/350 [==============================] - 22s 64ms/step - loss: 1.2630 - accuracy: 0.5229 - val_loss: 1.6389 - val_accuracy: 0.4464\n",
            "Epoch 35/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.1580 - accuracy: 0.5400 - val_loss: 1.5845 - val_accuracy: 0.3929\n",
            "Epoch 36/100\n",
            "350/350 [==============================] - 20s 58ms/step - loss: 1.1586 - accuracy: 0.5429 - val_loss: 1.5757 - val_accuracy: 0.5000\n",
            "Epoch 37/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 1.1972 - accuracy: 0.5714 - val_loss: 1.5194 - val_accuracy: 0.4821\n",
            "Epoch 38/100\n",
            "350/350 [==============================] - 23s 65ms/step - loss: 1.1353 - accuracy: 0.5800 - val_loss: 1.5758 - val_accuracy: 0.5000\n",
            "Epoch 39/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 1.0597 - accuracy: 0.6200 - val_loss: 1.6541 - val_accuracy: 0.4107\n",
            "Epoch 40/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 1.0253 - accuracy: 0.5914 - val_loss: 1.6574 - val_accuracy: 0.4464\n",
            "Epoch 41/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 1.0436 - accuracy: 0.5971 - val_loss: 1.6165 - val_accuracy: 0.5000\n",
            "Epoch 42/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 1.0657 - accuracy: 0.6114 - val_loss: 1.4716 - val_accuracy: 0.5714\n",
            "Epoch 43/100\n",
            "350/350 [==============================] - 20s 57ms/step - loss: 1.0282 - accuracy: 0.6514 - val_loss: 1.6251 - val_accuracy: 0.4286\n",
            "Epoch 44/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 1.0223 - accuracy: 0.6286 - val_loss: 1.6957 - val_accuracy: 0.3929\n",
            "Epoch 45/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.9957 - accuracy: 0.6371 - val_loss: 1.5682 - val_accuracy: 0.4643\n",
            "Epoch 46/100\n",
            "350/350 [==============================] - 20s 58ms/step - loss: 0.9802 - accuracy: 0.6429 - val_loss: 1.9964 - val_accuracy: 0.4464\n",
            "Epoch 47/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.9399 - accuracy: 0.6143 - val_loss: 1.6740 - val_accuracy: 0.4286\n",
            "Epoch 48/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.9441 - accuracy: 0.6086 - val_loss: 1.5986 - val_accuracy: 0.4464\n",
            "Epoch 49/100\n",
            "350/350 [==============================] - 22s 64ms/step - loss: 0.9384 - accuracy: 0.6314 - val_loss: 1.5300 - val_accuracy: 0.5000\n",
            "Epoch 50/100\n",
            "350/350 [==============================] - 22s 64ms/step - loss: 0.9125 - accuracy: 0.6657 - val_loss: 1.5574 - val_accuracy: 0.4821\n",
            "Epoch 51/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.8934 - accuracy: 0.6600 - val_loss: 1.4855 - val_accuracy: 0.5357\n",
            "Epoch 52/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.9166 - accuracy: 0.6400 - val_loss: 1.5225 - val_accuracy: 0.4821\n",
            "Epoch 53/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.8456 - accuracy: 0.6857 - val_loss: 1.7789 - val_accuracy: 0.4643\n",
            "Epoch 54/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.9206 - accuracy: 0.6457 - val_loss: 1.5492 - val_accuracy: 0.4286\n",
            "Epoch 55/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.8328 - accuracy: 0.6886 - val_loss: 1.5140 - val_accuracy: 0.5179\n",
            "Epoch 56/100\n",
            "350/350 [==============================] - 23s 65ms/step - loss: 0.9637 - accuracy: 0.6200 - val_loss: 1.5397 - val_accuracy: 0.5179\n",
            "Epoch 57/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.8405 - accuracy: 0.6771 - val_loss: 1.6967 - val_accuracy: 0.4286\n",
            "Epoch 58/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.8347 - accuracy: 0.7143 - val_loss: 1.8410 - val_accuracy: 0.4464\n",
            "Epoch 59/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.8266 - accuracy: 0.6714 - val_loss: 1.6184 - val_accuracy: 0.4286\n",
            "Epoch 60/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.7854 - accuracy: 0.7229 - val_loss: 1.8012 - val_accuracy: 0.4821\n",
            "Epoch 61/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.7866 - accuracy: 0.7086 - val_loss: 2.0548 - val_accuracy: 0.4286\n",
            "Epoch 62/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.7492 - accuracy: 0.7286 - val_loss: 1.7092 - val_accuracy: 0.4464\n",
            "Epoch 63/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.8137 - accuracy: 0.6743 - val_loss: 1.5033 - val_accuracy: 0.5357\n",
            "Epoch 64/100\n",
            "350/350 [==============================] - 20s 59ms/step - loss: 0.7412 - accuracy: 0.7314 - val_loss: 1.6365 - val_accuracy: 0.4464\n",
            "Epoch 65/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.7313 - accuracy: 0.7314 - val_loss: 1.8205 - val_accuracy: 0.4643\n",
            "Epoch 66/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.7252 - accuracy: 0.7200 - val_loss: 1.9069 - val_accuracy: 0.4821\n",
            "Epoch 67/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.7027 - accuracy: 0.7314 - val_loss: 1.8182 - val_accuracy: 0.4464\n",
            "Epoch 68/100\n",
            "350/350 [==============================] - 22s 64ms/step - loss: 0.7000 - accuracy: 0.7400 - val_loss: 1.6834 - val_accuracy: 0.4643\n",
            "Epoch 69/100\n",
            "350/350 [==============================] - 20s 57ms/step - loss: 0.6827 - accuracy: 0.7543 - val_loss: 1.5272 - val_accuracy: 0.5000\n",
            "Epoch 70/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.7012 - accuracy: 0.7114 - val_loss: 1.6796 - val_accuracy: 0.4821\n",
            "Epoch 71/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.6555 - accuracy: 0.7343 - val_loss: 2.0071 - val_accuracy: 0.4464\n",
            "Epoch 72/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.7126 - accuracy: 0.7486 - val_loss: 1.8239 - val_accuracy: 0.5179\n",
            "Epoch 73/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.6678 - accuracy: 0.7514 - val_loss: 1.6813 - val_accuracy: 0.3929\n",
            "Epoch 74/100\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 0.7032 - accuracy: 0.7286 - val_loss: 1.8202 - val_accuracy: 0.4464\n",
            "Epoch 75/100\n",
            "350/350 [==============================] - 26s 75ms/step - loss: 0.6235 - accuracy: 0.7714 - val_loss: 1.7674 - val_accuracy: 0.4464\n",
            "Epoch 76/100\n",
            "350/350 [==============================] - 28s 79ms/step - loss: 0.6221 - accuracy: 0.7514 - val_loss: 1.7199 - val_accuracy: 0.5714\n",
            "Epoch 77/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.6435 - accuracy: 0.7543 - val_loss: 1.8308 - val_accuracy: 0.5357\n",
            "Epoch 78/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.6880 - accuracy: 0.7200 - val_loss: 1.9924 - val_accuracy: 0.5357\n",
            "Epoch 79/100\n",
            "350/350 [==============================] - 23s 66ms/step - loss: 0.5965 - accuracy: 0.7457 - val_loss: 1.8887 - val_accuracy: 0.4286\n",
            "Epoch 80/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.6369 - accuracy: 0.7600 - val_loss: 1.6759 - val_accuracy: 0.4821\n",
            "Epoch 81/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.6353 - accuracy: 0.7400 - val_loss: 1.8931 - val_accuracy: 0.4643\n",
            "Epoch 82/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.5385 - accuracy: 0.7914 - val_loss: 1.8432 - val_accuracy: 0.4643\n",
            "Epoch 83/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.5580 - accuracy: 0.7886 - val_loss: 2.1621 - val_accuracy: 0.4286\n",
            "Epoch 84/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.6047 - accuracy: 0.7743 - val_loss: 1.6383 - val_accuracy: 0.4643\n",
            "Epoch 85/100\n",
            "350/350 [==============================] - 23s 64ms/step - loss: 0.4842 - accuracy: 0.8286 - val_loss: 2.0212 - val_accuracy: 0.4107\n",
            "Epoch 86/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.5573 - accuracy: 0.7971 - val_loss: 1.8244 - val_accuracy: 0.4643\n",
            "Epoch 87/100\n",
            "350/350 [==============================] - 21s 61ms/step - loss: 0.5677 - accuracy: 0.7771 - val_loss: 2.0147 - val_accuracy: 0.4643\n",
            "Epoch 88/100\n",
            "350/350 [==============================] - 23s 66ms/step - loss: 0.5451 - accuracy: 0.8086 - val_loss: 1.9683 - val_accuracy: 0.4286\n",
            "Epoch 89/100\n",
            "350/350 [==============================] - 22s 63ms/step - loss: 0.5381 - accuracy: 0.7800 - val_loss: 2.1165 - val_accuracy: 0.4107\n",
            "Epoch 90/100\n",
            "350/350 [==============================] - 20s 58ms/step - loss: 0.5013 - accuracy: 0.8000 - val_loss: 1.7784 - val_accuracy: 0.5179\n",
            "Epoch 91/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.4616 - accuracy: 0.8200 - val_loss: 1.7356 - val_accuracy: 0.4107\n",
            "Epoch 92/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.5348 - accuracy: 0.7714 - val_loss: 1.7667 - val_accuracy: 0.4643\n",
            "Epoch 93/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.5397 - accuracy: 0.8029 - val_loss: 1.7658 - val_accuracy: 0.4643\n",
            "Epoch 94/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.4735 - accuracy: 0.8171 - val_loss: 1.8260 - val_accuracy: 0.4286\n",
            "Epoch 95/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.5183 - accuracy: 0.8086 - val_loss: 1.8652 - val_accuracy: 0.4464\n",
            "Epoch 96/100\n",
            "350/350 [==============================] - 22s 62ms/step - loss: 0.4788 - accuracy: 0.8229 - val_loss: 1.9407 - val_accuracy: 0.4464\n",
            "Epoch 97/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.4729 - accuracy: 0.8371 - val_loss: 2.1210 - val_accuracy: 0.4643\n",
            "Epoch 98/100\n",
            "350/350 [==============================] - 21s 60ms/step - loss: 0.4757 - accuracy: 0.8486 - val_loss: 2.0684 - val_accuracy: 0.5000\n",
            "Epoch 99/100\n",
            "350/350 [==============================] - 23s 65ms/step - loss: 0.4961 - accuracy: 0.8086 - val_loss: 1.9883 - val_accuracy: 0.4286\n",
            "Epoch 100/100\n",
            "350/350 [==============================] - 21s 59ms/step - loss: 0.4995 - accuracy: 0.8343 - val_loss: 1.9364 - val_accuracy: 0.4286\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7a40dc101a20>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rom keras.models import load_model"
      ],
      "metadata": {
        "id": "b5MKBduflSnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_model.save('/content/drive/MyDrive/1 virtusa emoji/MODEL/emoji_model_v5.h5')"
      ],
      "metadata": {
        "id": "LEnFC9gAm39w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3bOwJECFEyck"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}